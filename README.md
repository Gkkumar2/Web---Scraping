# ğŸš— Sri Lankan Vehicle Listing Web Scrapers

This project includes **three independent Python scripts** that scrape vehicle listings from popular Sri Lankan marketplaces:

- ğŸ”¹ [Patpat.lk](https://www.patpat.lk/)
- ğŸ”¹ [Autome.lk](https://autome.lk/)
- ğŸ”¹ [Hitad.lk](https://www.hitad.lk/)

Each script fetches car name, price, location, date posted, and link to the listing. The data is saved into a structured CSV file for further analysis or automation purposes.

---

## ğŸ“ Project Files

- `patpat.py` â€“ Scrapes listings from Patpat.lk
- `autome.py` â€“ Scrapes listings from Autome.lk
- `hitad.py` â€“ Scrapes listings from Hitad.lk
- `requirements.txt` â€“ Required Python dependencies
- `README.md` â€“ Documentation and usage instructions

---

## ğŸ›  Installation & Setup

1. **Install Python 3.7+**

2. **Install dependencies:**

```bash
pip install -r requirements.txt
---
```
## ğŸ“¦ Requirements

Make sure you have the following Python libraries installed:

### `requirements.txt`

```text
selenium
webdriver-manager
beautifulsoup4
pandas
lxml
```
## ğŸš€ How to Run the Scripts
1ï¸âƒ£ Patpat.lk Scraper
- File: patpat.py

Output: patpat_car_data_all_pages.csv

Scrapes up to MAX_PAGES of vehicle listings and extracts:

- Title
- Price
- Date Posted
- Link

Run command:
```bash
python patpat.py
```

2ï¸âƒ£ Autome.lk Scraper
- File: autome.py

Output: autome_car_listings.csv

Scrapes listings using dynamic scrolling and extracts:

- Name
- Price
- Location
- Date Posted
- Link

Run command:

```bash
python autome.py
```

3ï¸âƒ£ Hitad.lk Scraper
- File: hitad_scraper.py

Output: hitad_vehicles_data.csv

Scrapes vehicle classifieds and extracts:

- Title
- Price
- Location
- Date Posted
- Link

Run command:

```bash
python hitad.py
```

### ğŸ’¡ Use Cases
- ğŸ” Price comparison across multiple marketplaces

- ğŸ“Š Market analysis and tracking trends in Sri Lankan vehicle pricing

- ğŸ“‚ Automated data collection for dealerships and aggregators

- ğŸ§  Machine learning datasets for vehicle price prediction or recommendation models

### âš ï¸ Notes
- All scrapers use headless Chrome for background operation.

- ChromeDriver is auto-managed via webdriver-manager.

- If the website layout changes, you may need to update the HTML selectors.

- You can control how many pages are scraped using the MAX_PAGES variable in each script.

